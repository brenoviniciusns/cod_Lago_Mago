{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "401ab9e7-7f6f-4f71-8294-80e2c55f9da1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = '''SELECT owner_username as autor, slug \n",
    "FROM silver.tabnews.assunto\n",
    "WHERE body IS NULL\n",
    "LIMIT 50'''\n",
    "resposta = spark.sql(query).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36c15806-9c90-4448-8c6f-38ed9912f2f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "from typing import Optional, Dict, Any, List, Tuple\n",
    "import logging\n",
    "\n",
    "# Configuração básica de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "async def buscar_conteudo_TabNews_async(session: aiohttp.ClientSession, autor: str, slug: str) -> Tuple[Optional[Dict[str, Any]], str]:\n",
    "    \"\"\"\n",
    "    Busca o conteúdo do TabNews de forma assíncrona com tratamento de erros detalhado.\n",
    "\n",
    "    Args:\n",
    "        session: A sessão aiohttp para reutilização de conexão.\n",
    "        autor: O autor do conteúdo.\n",
    "        slug: O slug do conteúdo.\n",
    "\n",
    "    Returns:\n",
    "        Uma tupla contendo:\n",
    "        - Um dicionário com os dados do conteúdo, ou None em caso de erro.\n",
    "        - Uma string com a URL da requisição (para rastreamento e logs).\n",
    "    \"\"\"\n",
    "    url = f'https://www.tabnews.com.br/api/v1/contents/{autor}/{slug}'\n",
    "    try:\n",
    "        async with session.get(url, timeout=aiohttp.ClientTimeout(total=5)) as resposta:\n",
    "            #resposta.raise_for_status()  # Lança uma exceção para status HTTP de erro\n",
    "            dados = await resposta.json()\n",
    "            logging.info(f'Dados obtidos com sucesso para {url}')\n",
    "            return dados, url\n",
    "    except aiohttp.ClientError as erro:\n",
    "        logging.error(f'Erro ao buscar dados da API do TabNews para {url}: {erro}')\n",
    "        return None, url\n",
    "    except asyncio.TimeoutError:\n",
    "        logging.error(f'Timeout ao buscar dados da API do TabNews para {url}')\n",
    "        return None, url\n",
    "    except Exception as erro:\n",
    "        logging.exception(f'Erro inesperado ao buscar dados da API do TabNews para {url}: {erro}')\n",
    "        return None, url\n",
    "\n",
    "async def buscar_conteudo_TabNews(autor: str, slug: str) -> Tuple[Optional[Dict[str, Any]], str]:\n",
    "    \"\"\"\n",
    "    Função para buscar o conteúdo do TabNews, encapsulando a sessão aiohttp.\n",
    "\n",
    "    Args:\n",
    "        autor: O autor do conteúdo.\n",
    "        slug: O slug do conteúdo.\n",
    "\n",
    "    Returns:\n",
    "        Uma tupla contendo:\n",
    "        - Um dicionário com os dados do conteúdo, ou None em caso de erro.\n",
    "        - Uma string com a URL da requisição.\n",
    "    \"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        return await buscar_conteudo_TabNews_async(session, autor, slug)\n",
    "\n",
    "# Função para processar uma única resposta de forma assíncrona\n",
    "async def processar_resposta(r) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Processa uma resposta individual, buscando o conteúdo do TabNews e tratando possíveis erros.\n",
    "\n",
    "    Args:\n",
    "        r: Um objeto contendo os atributos 'autor' e 'slug'.\n",
    "\n",
    "    Returns:\n",
    "        Um dicionário contendo os dados da resposta, ou um dicionário de erro.\n",
    "    \"\"\"\n",
    "    autor, slug = r.autor, r.slug\n",
    "    dados, url = await buscar_conteudo_TabNews(autor, slug)\n",
    "    if dados:\n",
    "        return {'url': url, 'data': dados}\n",
    "    else:\n",
    "        return {'url': url, 'error': 'Falha ao obter dados'}\n",
    "\n",
    "# Função principal que será chamada para processar todas as respostas\n",
    "async def processar_todas_respostas(resposta: List[Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Processa todas as respostas de forma assíncrona, utilizando asyncio.gather para paralelização.\n",
    "\n",
    "    Args:\n",
    "        resposta: Uma lista de objetos, cada um contendo os atributos 'autor' e 'slug'.\n",
    "\n",
    "    Returns:\n",
    "        Uma lista de dicionários, cada um contendo os dados da resposta ou informações de erro.\n",
    "    \"\"\"\n",
    "    tarefas = [processar_resposta(r) for r in resposta]\n",
    "    resultados = await asyncio.gather(*tarefas, return_exceptions=True)  # Captura exceções individuais\n",
    "    \n",
    "    # Tratamento de possíveis exceções não capturadas dentro de processar_resposta\n",
    "    resultados_tratados = []\n",
    "    for resultado in resultados:\n",
    "        if isinstance(resultado, Exception):\n",
    "            logging.error(f'Exceção não tratada: {resultado}')\n",
    "            resultados_tratados.append({'error': str(resultado)})\n",
    "        else:\n",
    "            resultados_tratados.append(resultado)\n",
    "    \n",
    "    return resultados_tratados\n",
    "\n",
    "# Uso em um notebook Jupyter\n",
    "async def main(resposta: List[Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Função principal para execução em ambiente Jupyter Notebook.\n",
    "\n",
    "    Args:\n",
    "        resposta: Uma lista de objetos, cada um contendo os atributos 'autor' e 'slug'.\n",
    "\n",
    "    Returns:\n",
    "        Uma lista de dicionários contendo os resultados do processamento.\n",
    "    \"\"\"\n",
    "    return await processar_todas_respostas(resposta)\n",
    "\n",
    "# Supondo que 'resposta' já existe e contém os dados\n",
    "# Para executar, use:\n",
    "resultados_assync = await main(resposta)\n",
    "# (Em um ambiente Jupyter Notebook com suporte a asyncio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ed31114-df10-4637-a666-a6f3a3d39b92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def flatten_item(item):\n",
    "    \"\"\"\n",
    "    Extrai informações relevantes de um item, movendo os dados aninhados para o nível superior.\n",
    "\n",
    "    Args:\n",
    "        item (dict): Um dicionário contendo a URL, dados (se existirem) e erros (se existirem).\n",
    "\n",
    "    Returns:\n",
    "        dict: Um dicionário \"achatado\" com a URL, dados extraídos e informações de erro.\n",
    "    \"\"\"\n",
    "    flat = {'url': item['url']}  # Inicializa o dicionário flat com a URL do item.\n",
    "    flat.update(item.get('data', {}))  # Adiciona os dados do item, se existirem, ao dicionário flat.\n",
    "    flat['error'] = item.get('error')  # Adiciona informações de erro, se existirem, ao dicionário flat.\n",
    "    return flat\n",
    "\n",
    "# Cria um DataFrame pandas a partir dos dados \"achatados\".\n",
    "df_assync = pd.DataFrame([flatten_item(item) for item in resultados_assync])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9514627-f39a-4154-8bc5-21179a664b31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Carregue a tabela existente Delta\n",
    "delta_table = DeltaTable.forName(spark, \"silver.tabnews.assunto\")\n",
    "df_assync_spark = spark.createDataFrame(df_assync)\n",
    "# Realize o merge usando o Delta Lake\n",
    "delta_table.alias(\"target\") \\\n",
    "    .merge(\n",
    "        df_assync_spark.alias(\"updates\"),\n",
    "        \"target.id = updates.id\"\n",
    "    ) \\\n",
    "    .whenMatchedUpdate(set={\n",
    "        \"url\": col(\"updates.url\"),\n",
    "        \"body\": col(\"updates.body\")\n",
    "    }) \\\n",
    "    .whenNotMatchedInsert(values={\n",
    "        \"id\": col(\"updates.id\"),\n",
    "        \"url\": col(\"updates.url\"),\n",
    "        \"body\": col(\"updates.body\")\n",
    "    }) \\\n",
    "    .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a25fda48-ace6-40fb-adf2-4849be56b4cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2351476223448377,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Buscando as publicações completas",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
