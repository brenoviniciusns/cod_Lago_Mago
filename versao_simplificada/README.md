# TabNews Data Engineering Extractor

## ğŸ“‹ DescriÃ§Ã£o

Esta Ã© uma versÃ£o **simplificada** do projeto Lago Mago, focada exclusivamente em extrair publicaÃ§Ãµes do TabNews relacionadas Ã  **Engenharia de Dados** e salvar os resultados em um arquivo Excel.

## ğŸ¯ Objetivo

Coletar e organizar publicaÃ§Ãµes relevantes sobre Engenharia de Dados do TabNews em um formato Excel (.xlsx) para anÃ¡lise posterior.

## ğŸš€ Funcionalidades

- âœ… **Busca automÃ¡tica** de publicaÃ§Ãµes na API do TabNews
- âœ… **Filtro inteligente** por palavras-chave de Engenharia de Dados
- âœ… **Coleta assÃ­ncrona** do conteÃºdo completo dos posts relevantes
- âœ… **ExportaÃ§Ã£o para Excel** com mÃºltiplas planilhas
- âœ… **Logging detalhado** para acompanhar o processo
- âœ… **Tratamento de erros** robusto
- âœ… **ConfiguraÃ§Ã£o personalizÃ¡vel**
- âœ… **Exemplos de uso** incluÃ­dos

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 2. Executar o script

```bash
# ExecuÃ§Ã£o simples
python tabnews_extractor.py

# Ou executar exemplos de uso
python exemplo_uso.py
```

## ï¿½ Arquivos do Projeto

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| `tabnews_extractor.py` | Script principal com a classe TabNewsDataExtractor |
| `requirements.txt` | DependÃªncias do projeto |
| `config.py` | ConfiguraÃ§Ãµes personalizÃ¡veis |
| `exemplo_uso.py` | Exemplos de como usar o extractor |
| `README.md` | Este arquivo de documentaÃ§Ã£o |

## ï¿½ğŸ”§ ConfiguraÃ§Ã£o

VocÃª pode personalizar o comportamento editando as configuraÃ§Ãµes em `config.py` ou diretamente no cÃ³digo:

```python
# ConfiguraÃ§Ãµes bÃ¡sicas na funÃ§Ã£o main()
PAGINAS = 10        # NÃºmero de pÃ¡ginas para buscar
POR_PAGINA = 30     # Itens por pÃ¡gina
ARQUIVO_SAIDA = None  # None para nome automÃ¡tico
```

## ğŸ’¡ Exemplos de Uso

### 1. Uso Simples (Script Principal)
```bash
python tabnews_extractor.py
```

### 2. Uso ProgramÃ¡tico
```python
import asyncio
from tabnews_extractor import TabNewsDataExtractor

async def meu_extractor():
    extractor = TabNewsDataExtractor()
    arquivo = await extractor.executar_pipeline_completo(
        paginas=5,
        por_pagina=20,
        arquivo_saida="meus_dados.xlsx"
    )
    print(f"Arquivo criado: {arquivo}")

asyncio.run(meu_extractor())
```

### 3. Pipeline Personalizado
```python
# Veja exemplos completos em exemplo_uso.py
python exemplo_uso.py
```

## ğŸ“Š Palavras-chave Utilizadas

O script filtra publicaÃ§Ãµes baseado nestas categorias de palavras-chave:

### ğŸ”§ Ferramentas ETL/Pipeline
- ETL, ELT, Data Pipeline
- Apache Airflow, Luigi, Prefect, Dagster

### ğŸš€ Big Data & Processamento
- Apache Spark, Hadoop, Hive, Presto, Trino
- Apache Flink, Apache Storm

### ğŸ—„ï¸ Bancos de Dados
- PostgreSQL, MySQL, MongoDB
- Redis, Elasticsearch, ClickHouse

### â˜ï¸ Cloud Data Platforms
- Snowflake, BigQuery, Redshift
- Databricks, AWS Glue, Azure Data Factory

### ğŸ“¡ Streaming & Real-time
- Apache Kafka, Apache Pulsar
- Stream Processing, Real-time Data

### ğŸ“„ Formatos de Dados
- Parquet, Avro, ORC
- Delta Lake, Apache Iceberg

### ğŸ›ï¸ Data Quality & Governance
- Data Quality, Data Validation
- Data Lineage, Data Governance

*Lista completa disponÃ­vel em `config.py`*

## ğŸ“ˆ Arquivo Excel Gerado

O arquivo Excel contÃ©m **3 planilhas**:

### 1. **PublicaÃ§Ãµes** (dados principais)
| Coluna | DescriÃ§Ã£o |
|--------|-----------|
| ID | Identificador Ãºnico |
| TÃ­tulo | TÃ­tulo da publicaÃ§Ã£o |
| Autor | Nome do autor |
| Data CriaÃ§Ã£o/AtualizaÃ§Ã£o | Timestamps |
| TabCoins | PontuaÃ§Ã£o/relevÃ¢ncia |
| Palavras-chave Encontradas | Palavras que ativaram o filtro |
| ConteÃºdo (InÃ­cio) | Primeiros 500 caracteres |
| URL, Slug, Status | Metadados tÃ©cnicos |

### 2. **EstatÃ­sticas**
- Total de publicaÃ§Ãµes
- PublicaÃ§Ãµes com/sem conteÃºdo
- MÃ©tricas de TabCoins
- Autores Ãºnicos
- Data da extraÃ§Ã£o

### 3. **Palavras-chave**
- Lista completa das palavras-chave utilizadas

## ğŸ”„ ComparaÃ§Ã£o com a VersÃ£o Original

| VersÃ£o Original (Spark) | VersÃ£o Simplificada |
|-------------------------|---------------------|
| Multiple notebooks | 1 arquivo Python |
| Apache Spark/Databricks | Pandas + requests |
| Delta Lake | Arquivo Excel |
| Complexo pipeline | Pipeline linear simples |
| MÃºltiplas dependÃªncias | DependÃªncias mÃ­nimas |
| ConfiguraÃ§Ã£o complexa | ConfiguraÃ§Ã£o simples |

## ğŸ“ Log de ExecuÃ§Ã£o

O script fornece logs detalhados durante a execuÃ§Ã£o:

```
ğŸš€ TabNews Data Engineering Scraper
==================================================
2025-08-05 20:37:28 - INFO - === INICIANDO PIPELINE DE EXTRAÃ‡ÃƒO TABNEWS ===
2025-08-05 20:37:28 - INFO - Iniciando busca de publicaÃ§Ãµes - 10 pÃ¡ginas, 30 por pÃ¡gina
2025-08-05 20:37:30 - INFO - PÃ¡gina 1: 30 publicaÃ§Ãµes obtidas
...
2025-08-05 20:37:44 - INFO - PublicaÃ§Ãµes relevantes encontradas: 9
2025-08-05 20:37:47 - INFO - ConteÃºdos completos obtidos: 9
2025-08-05 20:37:48 - INFO - Arquivo Excel salvo com sucesso
âœ… Sucesso! Arquivo Excel criado: publicacoes_engenharia_dados_20250805_203748.xlsx
```

## ğŸ› ï¸ DependÃªncias

```
requests==2.31.0      # Para chamadas Ã  API
pandas==2.1.4         # Para manipulaÃ§Ã£o de dados  
openpyxl==3.1.2       # Para geraÃ§Ã£o de arquivos Excel
aiohttp==3.9.1        # Para requisiÃ§Ãµes assÃ­ncronas
asyncio-throttle==1.0.2  # Para controle de requisiÃ§Ãµes
urllib3==2.0.7        # Para tratamento de SSL
```

## âš¡ Performance & CaracterÃ­sticas

- âœ… **RequisiÃ§Ãµes assÃ­ncronas** para melhor performance
- âœ… **Limite de 5 requisiÃ§Ãµes simultÃ¢neas** para nÃ£o sobrecarregar a API
- âœ… **Tratamento de SSL** para ambientes corporativos
- âœ… **Processamento eficiente** com pandas
- âœ… **Logs detalhados** para acompanhamento
- âœ… **Tratamento robusto de erros**

## ğŸ”§ PersonalizaÃ§Ã£o

### Alterar Palavras-chave
Edite a lista `PALAVRAS_CHAVE_CUSTOM` em `config.py`.

### Alterar ConfiguraÃ§Ãµes da API
Modifique as constantes no inÃ­cio de `config.py`:
```python
PAGINAS_PADRAO = 10
ITENS_POR_PAGINA = 30
MAX_REQUISICOES_SIMULTANEAS = 5
```

### Personalizar SaÃ­da Excel
Modifique os mÃ©todos `preparar_dados_para_excel()` e `salvar_excel()` na classe principal.

## ğŸš€ Resultados

O script jÃ¡ foi testado com sucesso:
- âœ… 300 publicaÃ§Ãµes analisadas (10 pÃ¡ginas Ã— 30 itens)
- âœ… 9 publicaÃ§Ãµes relevantes encontradas
- âœ… Arquivo Excel gerado com 3 planilhas
- âœ… Tempo de execuÃ§Ã£o: ~20 segundos
- âœ… Taxa de sucesso: 100% das requisiÃ§Ãµes

## ğŸ“„ LicenÃ§a

Este projeto Ã© uma versÃ£o simplificada do Lago Mago original.
